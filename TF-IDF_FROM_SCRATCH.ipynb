{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1348dbbe-b22a-4e35-9c1a-aec539859284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "655549e1-c04b-4350-92d9-1e6639a87fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tiwar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The 'punkt' package is required for tokenizing text into words and sentences.\n",
    "# By downloading 'punkt', we ensure that we have the necessary resources to perform tokenization.\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b324ca6-b620-4d3f-be2b-8cea11d4b426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding 'r' means that backslashes (\\) in the string are treated as literal backslashes and not as escape characters.\n",
    "df = pd.read_csv(r\"C:\\Users\\tiwar\\Downloads\\bbc_text_cls.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "337538dc-c347-4b2e-abe5-096783656bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    labels\n",
       "0  Ad sales boost Time Warner profit\\n\\nQuarterly...  business\n",
       "1  Dollar gains on Greenspan speech\\n\\nThe dollar...  business\n",
       "2  Yukos unit buyer faces loan claim\\n\\nThe owner...  business\n",
       "3  High fuel prices hit BA's profits\\n\\nBritish A...  business\n",
       "4  Pernod takeover talk lifts Domecq\\n\\nShares in...  business"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddcc1473-21cd-4436-a812-6f46fbbcfb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting documents into sequences of indices basically (index).\n",
    "idx = 0\n",
    "word2idx = {}  #{'ad': 0, 'sales': 1, 'boost': 2, 'time': 3, ..........\n",
    "tokenized_docs = []\n",
    "for doc in df['text']:\n",
    "    words = word_tokenize(doc.lower())\n",
    "    doc_as_int = []\n",
    "    for word in words:\n",
    "        if word not in word2idx:\n",
    "            word2idx[word] = idx\n",
    "            idx += 1\n",
    "        doc_as_int.append(word2idx[word])\n",
    "    tokenized_docs.append(doc_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50faa35b-85df-4744-8aab-409654e97b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse mapping\n",
    "idx2word = {v:k for k,v in word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d167100-8bb5-4835-86a8-4f8522d88d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2225\n"
     ]
    }
   ],
   "source": [
    "# number of documents\n",
    "N = len(df['text'])\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd30a39a-74a9-411e-95eb-d5d54d5fbcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34762\n"
     ]
    }
   ],
   "source": [
    "# number of words\n",
    "V = len(word2idx)\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ca74cfd-46b4-450d-a3b2-216951587ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a N X V matrix where all the cell is filled with zeros\n",
    "tf = np.zeros((N,V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "714f1482-5146-4e0f-82f8-f27f5fd55412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 4. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# count the occurrences of each token in each document, thereby creating a term frequency representation (vector) of the documents.\n",
    "for i, doc_as_int in enumerate(tokenized_docs):\n",
    "    for j in doc_as_int:\n",
    "        tf[i,j] += 1\n",
    "print(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cffe3e8c-9039-43d0-8b8a-06397370c8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 12 204 127 ...   1   1   1]\n",
      "[5.22260554 2.3893922  2.86332511 ... 7.70751219 7.70751219 7.70751219]\n"
     ]
    }
   ],
   "source": [
    "# compute IDF\n",
    "document_freq = np.sum(tf > 0, axis=0) # [ 12 204 127 ...  (sum of the elements of each column in tf matrix.)\n",
    "idf = np.log(N/document_freq)\n",
    "print(document_freq)\n",
    "print(idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58668b44-bf6e-4300-938d-40504a99eadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.22260554 9.5575688  2.86332511 ... 0.         0.         0.        ]\n",
      " [0.         0.         2.86332511 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 7.70751219 7.70751219 7.70751219]]\n"
     ]
    }
   ],
   "source": [
    "#compute TF-IDF\n",
    "tf_idf = tf*idf\n",
    "print(tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c026f14-bdc1-408a-9571-e9bdcd44822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed() - it ensures that the random numbers generated are the same every time you run the code. This is important for reproducibility, so you or others can get consistent results and debug effectively. Without it, you'll get different random numbers on each run, making it hard to replicate results.\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ee90829-a8bf-4a73-ad1d-a33a19bb0efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: politics\n",
      "Text: Clarke faces ID cards rebellion\n",
      "Top 5 terms:\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[ 1931  1592 23370 ... 11738 11752 34761]\n",
      "cards\n",
      "clarke\n",
      "rebellion\n",
      "id\n",
      "bill\n"
     ]
    }
   ],
   "source": [
    "# Pick a random document, show the top 5 terms (in terms of tf_idf score)\n",
    "i = np.random.choice(N)\n",
    "row = df.iloc[i] #This will return one row to df\n",
    "print(\"Label:\", row[\"labels\"])\n",
    "print(\"Text:\", row[\"text\"].split(\"\\n\",1)[0])\n",
    "print(\"Top 5 terms:\")\n",
    "\n",
    "scores = tf_idf[i]\n",
    "print(scores)\n",
    "# argsort() sorts in ascending order by default and provides the indices of the terms sorted by their importance\n",
    "indices = (-scores).argsort()\n",
    "print(indices)\n",
    "\n",
    "for j in indices[:5]:\n",
    "    print(idx2word[j])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
